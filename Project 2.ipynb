{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import dirname, join as pjoin\n",
    "from scipy import io as sio\n",
    "#from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import datasets\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104000 training samples\n",
      "20800 validation samples\n",
      "20800 test samples\n",
      "(20800, 784) (20800, 26)\n"
     ]
    }
   ],
   "source": [
    "num_classes = 26\n",
    "batch_size = 2000\n",
    "epochs = 20\n",
    "neurons = 1000\n",
    "\n",
    "mat_contents = sio.loadmat('ANN-Handwritten-Char-Recognition-master/matlab/emnist-letters.mat')\n",
    "data = mat_contents['dataset']\n",
    "\n",
    "X_train = data['train'][0,0]['images'][0,0]\n",
    "y_train = data['train'][0,0]['labels'][0,0]\n",
    "X_test = data['test'][0,0]['images'][0,0]\n",
    "y_test = data['test'][0,0]['labels'][0,0]\n",
    "\n",
    "val_start = X_train.shape[0] - X_test.shape[0]\n",
    "X_val = X_train[val_start:X_train.shape[0],:]\n",
    "y_val = y_train[val_start:X_train.shape[0]]\n",
    "X_train = X_train[0:val_start,:]\n",
    "y_train = y_train[0:val_start]\n",
    "\n",
    "y_train -=1\n",
    "y_val -=1\n",
    "y_test -=1\n",
    "\n",
    "#convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "print(X_train.shape[0], \"training samples\")\n",
    "print(X_val.shape[0], \"validation samples\")\n",
    "print(X_test.shape[0], \"test samples\")\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_54 (Dense)             (None, 1000)              785000    \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 26)                26026     \n",
      "=================================================================\n",
      "Total params: 1,812,026\n",
      "Trainable params: 1,812,026\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Dense(neurons, activation='relu', input_shape=(784,)))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(neurons, activation='relu'))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 104000 samples, validate on 20800 samples\n",
      "Epoch 1/20\n",
      "104000/104000 [==============================] - 5s 49us/sample - loss: 25.1851 - accuracy: 0.5053 - val_loss: 1.4425 - val_accuracy: 0.7067\n",
      "Epoch 2/20\n",
      "104000/104000 [==============================] - 5s 49us/sample - loss: 1.7533 - accuracy: 0.6494 - val_loss: 0.9943 - val_accuracy: 0.7601\n",
      "Epoch 3/20\n",
      "104000/104000 [==============================] - 5s 52us/sample - loss: 1.1599 - accuracy: 0.7311 - val_loss: 0.7186 - val_accuracy: 0.8029\n",
      "Epoch 4/20\n",
      "104000/104000 [==============================] - 6s 56us/sample - loss: 0.7906 - accuracy: 0.7862 - val_loss: 0.5711 - val_accuracy: 0.8312\n",
      "Epoch 5/20\n",
      "104000/104000 [==============================] - 6s 55us/sample - loss: 0.6291 - accuracy: 0.8201 - val_loss: 0.5041 - val_accuracy: 0.8533\n",
      "Epoch 6/20\n",
      "104000/104000 [==============================] - 6s 56us/sample - loss: 0.5426 - accuracy: 0.8403 - val_loss: 0.4547 - val_accuracy: 0.8684\n",
      "Epoch 7/20\n",
      "104000/104000 [==============================] - 6s 57us/sample - loss: 0.4822 - accuracy: 0.8570 - val_loss: 0.4203 - val_accuracy: 0.8725\n",
      "Epoch 8/20\n",
      "104000/104000 [==============================] - 6s 59us/sample - loss: 0.4390 - accuracy: 0.8682 - val_loss: 0.4383 - val_accuracy: 0.8823\n",
      "Epoch 9/20\n",
      "104000/104000 [==============================] - 6s 58us/sample - loss: 0.4172 - accuracy: 0.8732 - val_loss: 0.4086 - val_accuracy: 0.8822\n",
      "Epoch 10/20\n",
      "104000/104000 [==============================] - 6s 58us/sample - loss: 0.3867 - accuracy: 0.8813 - val_loss: 0.3973 - val_accuracy: 0.8861\n",
      "Epoch 11/20\n",
      "104000/104000 [==============================] - 6s 58us/sample - loss: 0.3644 - accuracy: 0.8875 - val_loss: 0.4244 - val_accuracy: 0.8757\n",
      "Epoch 12/20\n",
      "104000/104000 [==============================] - 6s 60us/sample - loss: 0.3517 - accuracy: 0.8904 - val_loss: 0.4103 - val_accuracy: 0.8914\n",
      "Epoch 13/20\n",
      "104000/104000 [==============================] - 6s 60us/sample - loss: 0.3420 - accuracy: 0.8950 - val_loss: 0.3821 - val_accuracy: 0.8937\n",
      "Epoch 14/20\n",
      "104000/104000 [==============================] - 6s 60us/sample - loss: 0.3249 - accuracy: 0.8990 - val_loss: 0.3944 - val_accuracy: 0.8993\n",
      "Epoch 15/20\n",
      "104000/104000 [==============================] - 6s 59us/sample - loss: 0.3159 - accuracy: 0.9026 - val_loss: 0.4037 - val_accuracy: 0.8971\n",
      "Epoch 16/20\n",
      "104000/104000 [==============================] - 6s 59us/sample - loss: 0.3073 - accuracy: 0.9043 - val_loss: 0.4214 - val_accuracy: 0.8964\n",
      "Epoch 17/20\n",
      "104000/104000 [==============================] - 7s 65us/sample - loss: 0.2990 - accuracy: 0.9082 - val_loss: 0.4249 - val_accuracy: 0.9017\n",
      "Epoch 18/20\n",
      "104000/104000 [==============================] - 6s 62us/sample - loss: 0.2966 - accuracy: 0.9089 - val_loss: 0.4061 - val_accuracy: 0.9000\n",
      "Epoch 19/20\n",
      "104000/104000 [==============================] - 6s 59us/sample - loss: 0.2839 - accuracy: 0.9123 - val_loss: 0.4064 - val_accuracy: 0.9046\n",
      "Epoch 20/20\n",
      "104000/104000 [==============================] - 6s 59us/sample - loss: 0.2810 - accuracy: 0.9131 - val_loss: 0.4235 - val_accuracy: 0.9007\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size = batch_size,\n",
    "                    epochs = epochs,\n",
    "                    verbose = 1,\n",
    "                    validation_data = (X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.4365356271742628\n",
      "Test accuracy: 0.9001923\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 20 epochs, 1000 batch size,  800 neurons - 89.69%\n",
    "##### 20 epochs, 2000 batch size,  800 neurons - 89.56%\n",
    "##### 20 epochs, 1000 batch size,  500 neurons - 88.58%\n",
    "##### 20 epochs, 1000 batch size, 1000 neurons - 89.85%\n",
    "##### 20 epochs, 2000 batch size, 1000 neurons - 90.25%\n",
    "##### 20 epochs, 2000 batch size,  800 neurons - 89.74%\n",
    "##### 20 epochs, 2000 batch size, 1200 neurons - 90.27%\n",
    "##### 20 epochs, 2500 batch size, 1200 neurons - 89.64%\n",
    "##### 15 epochs, 2000 batch size, 1200 neurons - 89.67%\n",
    "##### 20 epochs, 1500 batch size, 1200 neurons - 89.56%\n",
    "##### 20 epochs, 1500 batch size,  800 neurons - 89.57%\n",
    "##### 20 epochs, 1000 batch size,  800 neurons - 89.18%\n",
    "##### 20 epochs, 2000 batch size,  800 neurons - 89.81%\n",
    "##### 20 epochs, 2000 batch size, 1200 neurons - 89.62%\n",
    "##### 20 epochs, 2000 batch size, 1000 neurons - 90.02%\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "            \n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
